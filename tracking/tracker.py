import numpy as np
from tracking import kalman_filter_2d
from tracking.cost_function import (iou_batch, get_velocity, compute_velocity_similarity, 
                                     estimate_detection_velocity, compute_velocity_trend_similarity,
                                     compute_smooth_velocity_similarity)
from tracking.matching import associate_detections_to_trackers_fusion, associate_2D_to_3D_tracking, linear_assignment,associate_detections_to_tracks
from tracking.track_2d import Track_2D
from tracking.kalman_fileter_3d import  KalmanBoxTracker
from tracking.track_3d import Track_3D
from trackers.ocsort_embedding.embedding import EmbeddingComputer
from tracking.matching import compute_aw_new_metric


class Tracker:
    def __init__(self, max_age, n_init, embeddiong_off=False, aw_off=False, grid_off=False,app_off=True,**kwargs):
        self.max_age = max_age
        self.n_init = n_init
        self.tracks_3d = []
        self.tracks_2d = []
        self.track_id_3d = 0   # The id of 3D track is represented by an even number.3dè½¨è¿¹idç”±å¶æ•°è¡¨ç¤º
        self.track_id_2d = 1   # The id of 2D track is represented by an odd number.2dè½¨è¿¹IDä¸ºå¥‡æ•°
        self.unmatch_tracks_3d = []
        self.kf_2d = kalman_filter_2d.KalmanFilter()
        self.embedding_off = embeddiong_off
        self.aw_off = aw_off
        self.det_thresh = 0.2
        self.alpha_fixed_emb = 0.9
        self.grid_off = grid_off
        self.app_off = app_off
        self.mot_off = False
        self.embedder = EmbeddingComputer(grid_off=self.grid_off)
        
        # ========== é€Ÿåº¦è‡ªé€‚åº”å›æº¯å…³è”å‚æ•° ==========
        self.velocity_backtrack_enabled = True   # å¯ç”¨é€Ÿåº¦å›æº¯ âœ…
        self.velocity_threshold = 0.6            # é€Ÿåº¦ç›¸ä¼¼åº¦é˜ˆå€¼
        self.velocity_weight = 0.5               # é»˜è®¤é€Ÿåº¦æƒé‡ (0.5è¡¨ç¤ºé€Ÿåº¦å’Œä½ç½®å„å 50%)
        self.adaptive_weight = True              # å¯ç”¨è‡ªé€‚åº”é€Ÿåº¦æƒé‡ (æ–¹æ¡ˆB)
        self.detection_history = {}              # å†å²æ£€æµ‹ç¼“å­˜ {frame_id: detections}
        self.current_frame = 0                   # å½“å‰å¸§è®¡æ•°
        
        # ========== æ–¹æ¡ˆ3: å¤šå¸§å›æº¯å‚æ•° ==========
        self.use_velocity_trend = True          # æš‚æ—¶ç¦ç”¨ (è°ƒè¯•é‡å¤IDé—®é¢˜) âŒ
        self.use_smooth_velocity = True         # æš‚æ—¶ç¦ç”¨ (è°ƒè¯•é‡å¤IDé—®é¢˜) âŒ
        self.velocity_smooth_window = 3          # é€Ÿåº¦å¹³æ»‘çª—å£å¤§å°
        self.trend_weight = 0.3                  # è¶‹åŠ¿æƒé‡ (0.3è¡¨ç¤º30%è¶‹åŠ¿ + 70%å½“å‰é€Ÿåº¦)

    def predict_3d(self):
        # print(self.tracks_3d)
        for track in self.tracks_3d:
            # print(track)
            track.predict_3d(track.kf_3d)

    def predict_2d(self):
        # print(self.tracks_2d)
        for track in self.tracks_2d:
            # print(track)
            track.predict_2d(self.kf_2d)

    def update(self, detection_3D_fusion, detection_3D_only, detection_3Dto2D_only, detection_2D_only, calib_file, img, detection_2D_only_conf, detection_3D_fusion_conf, iou_threshold):

        # generate embedding
        #åˆå§‹åŒ–
        dets_3D_fusion_embs = np.ones((len(detection_3D_fusion),1))
        dets_3D_only_embs = np.ones((len(detection_3D_only),1))
        dets_2D_only_embs = np.ones((len(detection_2D_only),1))
        det_3D_fusion_bboxs = [det_3d_f.additional_info[2:6] for det_3d_f in detection_3D_fusion]
        det_3D_only_bboxs = [det_3d_f.additional_info[2:6] for det_3d_f in detection_3D_only]
        det_2D_only_bboxs = [det_2d_f.bbox for det_2d_f in detection_2D_only]
        # å¾—åˆ°åµŒå…¥ç‰¹å¾
        if not self.app_off:
            if not self.embedding_off and dets_3D_fusion_embs.shape[0] != 0:
                dets_3D_fusion_embs = self.embedder.compute_embedding(img,det_3D_fusion_bboxs)
            if not self.embedding_off and dets_3D_only_embs.shape[0] != 0:
                dets_3D_only_embs = self.embedder.compute_embedding(img,det_3D_only_bboxs)
            if not self.embedding_off and dets_2D_only_embs.shape[0] != 0:
                dets_2D_only_embs = self.embedder.compute_embedding(img,det_2D_only_bboxs)
            # è®¡ç®—åµŒå…¥ç‰¹å¾çš„å¯ä¿¡åº¦
            if len(detection_3D_fusion_conf) != 0:
                trust_fusion = np.asarray([(i - self.det_thresh) / (1 - self.det_thresh) for i in detection_3D_fusion_conf])
            else:
                trust_fusion = np.asarray(list())
            if len(detection_2D_only_conf) != 0:
                trust_2D_only = np.asarray([(i - self.det_thresh) / (1 - self.det_thresh) for i in detection_2D_only_conf])
            else:
                trust_2D_only = np.asarray(list())
            af = self.alpha_fixed_emb
            # From [self.alpha_fixed_emb, 1], goes to 1 as detector is less confident
            if len(trust_fusion) != 0:
                dets_fusion_alpha = af + (1 - af) * (1 - trust_fusion)
            if len(trust_2D_only) != 0:
                dets_2d_only_alpha = af + (1 - af) * (1 - trust_2D_only)

        # æ›´æ–°å¸§è®¡æ•° (åœ¨å…³è”ä¹‹å‰)
        self.current_frame += 1

        # 1st Level of Association
        matched_fusion_idx, unmatched_dets_fusion_idx, unmatched_trks_fusion_idx = associate_detections_to_trackers_fusion(
            detection_3D_fusion, self.tracks_3d,self.aw_off,self.grid_off,self.mot_off, iou_threshold,det_embs=dets_3D_fusion_embs, det_app = self.app_off)
        for detection_idx, track_idx in matched_fusion_idx:
            self.tracks_3d[track_idx].update_3d(detection_3D_fusion[detection_idx])
            if not self.app_off:
                self.tracks_3d[track_idx].update_emb(dets_3D_fusion_embs[detection_idx])
            self.tracks_3d[track_idx].state = 2
            self.tracks_3d[track_idx].fusion_time_update = 0
        # ========== Level 1.5: é€Ÿåº¦è‡ªé€‚åº”å›æº¯å…³è” ==========
        # åœ¨å¤„ç†æœªåŒ¹é…ä¹‹å‰,å…ˆå°è¯•é€Ÿåº¦å›æº¯
        if self.velocity_backtrack_enabled and \
           len(unmatched_dets_fusion_idx) > 0 and \
           len(unmatched_trks_fusion_idx) > 0:
            
            print(f"[é€Ÿåº¦å›æº¯] æœªåŒ¹é…æ£€æµ‹: {len(unmatched_dets_fusion_idx)}, "
                  f"æœªåŒ¹é…è½¨è¿¹: {len(unmatched_trks_fusion_idx)}")
            
            # æå–æœªåŒ¹é…çš„æ£€æµ‹å’Œè½¨è¿¹
            unmatched_dets = [detection_3D_fusion[i] for i in unmatched_dets_fusion_idx]
            unmatched_trks = [self.tracks_3d[i] for i in unmatched_trks_fusion_idx]
            
            # é€Ÿåº¦å›æº¯å…³è”
            velocity_matched, velocity_unmatched_dets, velocity_unmatched_trks = \
                self._velocity_backtrack_association(
                    unmatched_dets, 
                    unmatched_trks,
                    dets_3D_fusion_embs,
                    unmatched_dets_fusion_idx
                )
            
            # æ›´æ–°åŒ¹é…æˆåŠŸçš„è½¨è¿¹
            for det_idx, trk_idx in velocity_matched:
                original_det_idx = unmatched_dets_fusion_idx[det_idx]
                original_trk_idx = unmatched_trks_fusion_idx[trk_idx]
                
                self.tracks_3d[original_trk_idx].update_3d(
                    detection_3D_fusion[original_det_idx]
                )
                if not self.app_off:
                    self.tracks_3d[original_trk_idx].update_emb(
                        dets_3D_fusion_embs[original_det_idx]
                    )
                self.tracks_3d[original_trk_idx].state = 2
                self.tracks_3d[original_trk_idx].fusion_time_update = 0
                
                print(f"[é€Ÿåº¦å›æº¯] âœ… æˆåŠŸåŒ¹é…: æ£€æµ‹{original_det_idx} â†” è½¨è¿¹{original_trk_idx}")
            
            # æ›´æ–°æœªåŒ¹é…åˆ—è¡¨ (åªä¿ç•™çœŸæ­£æœªåŒ¹é…çš„)
            unmatched_dets_fusion_idx = [
                unmatched_dets_fusion_idx[i] for i in velocity_unmatched_dets
            ]
            unmatched_trks_fusion_idx = [
                unmatched_trks_fusion_idx[i] for i in velocity_unmatched_trks
            ]
            
            if len(velocity_matched) > 0:
                print(f"[é€Ÿåº¦å›æº¯] ğŸ“Š æœ¬å¸§åŒ¹é…æˆåŠŸ: {len(velocity_matched)}å¯¹")
        
        # å¤„ç†æœ€ç»ˆæœªåŒ¹é…çš„è½¨è¿¹å’Œæ£€æµ‹
        for track_idx in unmatched_trks_fusion_idx:
            self.tracks_3d[track_idx].fusion_time_update += 1
            self.tracks_3d[track_idx].mark_missed()
        for detection_idx in unmatched_dets_fusion_idx:
            self._initiate_track_3d(detection_3D_fusion[detection_idx],dets_3D_fusion_embs[detection_idx])

        #  2nd Level of Association
        self.unmatch_tracks_3d1 = [t for t in self.tracks_3d if t.time_since_update > 0]
        matched_only_idx, unmatched_dets_only_idx, _ = associate_detections_to_trackers_fusion(
            detection_3D_only, self.unmatch_tracks_3d1,self.aw_off,self.grid_off,self.mot_off, iou_threshold, det_embs=dets_3D_only_embs, det_app=self.app_off)
        index_to_delete = []
        for detection_idx, track_idx in matched_only_idx:
            for index, t in enumerate(self.tracks_3d):
                if t.track_id_3d == self.unmatch_tracks_3d1[track_idx].track_id_3d:
                    t.update_3d(detection_3D_only[detection_idx])
                    if not self.app_off:
                        t.update_emb(dets_3D_only_embs[detection_idx])
                    index_to_delete.append(track_idx)
                    break
        self.unmatch_tracks_3d1 = [self.unmatch_tracks_3d1[i] for i in range(len(self.unmatch_tracks_3d1)) if i not in index_to_delete]
        for detection_idx in unmatched_dets_only_idx:
            self._initiate_track_3d(detection_3D_only[detection_idx],dets_3D_only_embs[detection_idx])
        self.unmatch_tracks_3d2 = [t for t in self.tracks_3d if t.time_since_update == 0 and t.hits == 1 ]
        self.unmatch_tracks_3d = self.unmatch_tracks_3d1 + self.unmatch_tracks_3d2

        # 3rd Level of Association
        matched, unmatch_trks, unmatch_dets = associate_detections_to_tracks(self.tracks_2d, detection_2D_only, iou_threshold, self.aw_off,self.grid_off,self.mot_off, det_embs=dets_2D_only_embs, det_app = self.app_off)
        for track_idx, detection_idx in matched:
            self.tracks_2d[track_idx].update_2d(self.kf_2d, detection_2D_only[detection_idx])
            if not self.app_off:
                self.tracks_2d[track_idx].update_emb(dets_2D_only_embs[detection_idx])
        for track_idx in unmatch_trks:
            self.tracks_2d[track_idx].mark_missed()
        for detection_idx in unmatch_dets:
            self._initiate_track_2d(detection_2D_only[detection_idx],dets_2D_only_embs[detection_idx])
        self.tracks_2d = [t for t in self.tracks_2d if not t.is_deleted()]

        #  4th Level of Association
        matched_track_2d, unmatch_tracks_2d = associate_2D_to_3D_tracking(self.tracks_2d, self.unmatch_tracks_3d, calib_file, iou_threshold)
        index_to_delete2 = []
        for track_idx_2d, track_idx_3d in matched_track_2d:
            for i in range(len(self.tracks_3d)):
                if self.tracks_3d[i].track_id_3d == self.unmatch_tracks_3d[track_idx_3d].track_id_3d:
                    self.tracks_3d[i].age = self.tracks_2d[track_idx_2d].age + 1
                    if self.tracks_3d[i].track_id_3d % 2 ==0:
                        new_id = self.tracks_2d[track_idx_2d].track_id_2d
                        # ========== ä¿®å¤: æ£€æŸ¥IDå”¯ä¸€æ€§ ==========
                        existing_ids = [t.track_id_3d for t in self.tracks_3d if t != self.tracks_3d[i]]
                        if new_id not in existing_ids:
                            # print(self.tracks_3d[i].track_id_3d,self.tracks_2d[track_idx_2d].track_id_2d)
                            self.tracks_3d[i].track_id_3d = new_id
                            # print("recite:",self.tracks_3d[i].track_id_3d)
                        else:
                            print(f"âš ï¸ è·³è¿‡IDä¿®æ”¹: {new_id} å·²å­˜åœ¨äºtracks_3dä¸­")
                        # ========================================
                    self.tracks_3d[i].time_since_update = 0
                    if self.tracks_2d[track_idx_2d].hits >= 2:
                        self.tracks_3d[i].hits = self.tracks_2d[track_idx_2d].hits + 1
                    else:
                        self.tracks_3d[i].hits += 1
                    self.tracks_3d[i].state_update()
            index_to_delete2.append(track_idx_2d)
        self.tracks_2d = [self.tracks_2d[i] for i in range(len(self.tracks_2d)) if i not in index_to_delete2]
        self.tracks_3d = [t for t in self.tracks_3d if not t.is_deleted()]
        
        # ========== DEBUG: æ£€æŸ¥é‡å¤ID ==========
        track_ids = [t.track_id_3d for t in self.tracks_3d if t.is_confirmed()]
        if len(track_ids) != len(set(track_ids)):
            from collections import Counter
            duplicates = [id for id, count in Counter(track_ids).items() if count > 1]
            print(f"âŒ è­¦å‘Šï¼šå‘ç°é‡å¤çš„è½¨è¿¹ID: {duplicates}")
            print(f"   æ‰€æœ‰ID: {track_ids}")
            print(f"   å¸§å·: {self.current_frame}")
        # ========================================
        
        # æ›´æ–°æ£€æµ‹å†å² (å¸§è®¡æ•°å·²åœ¨å‡½æ•°å¼€å§‹æ—¶æ›´æ–°)
        self._update_detection_history(detection_3D_fusion)

    def _velocity_backtrack_association(self, detections, tracks, det_embs, det_indices):
        """
        åŸºäºé€Ÿåº¦çš„å›æº¯å…³è”
        
        Args:
            detections: æœªåŒ¹é…çš„æ£€æµ‹åˆ—è¡¨
            tracks: æœªåŒ¹é…çš„è½¨è¿¹åˆ—è¡¨
            det_embs: æ£€æµ‹çš„åµŒå…¥ç‰¹å¾
            det_indices: æ£€æµ‹åœ¨åŸåˆ—è¡¨ä¸­çš„ç´¢å¼•
        
        Returns:
            matched: åŒ¹é…çš„ç´¢å¼•å¯¹ [(det_idx, trk_idx), ...]
            unmatched_dets: æœªåŒ¹é…çš„æ£€æµ‹ç´¢å¼•
            unmatched_trks: æœªåŒ¹é…çš„è½¨è¿¹ç´¢å¼•
        """
        if len(detections) == 0 or len(tracks) == 0:
            return [], list(range(len(detections))), list(range(len(tracks)))
        
        # 1. è®¡ç®—é€Ÿåº¦ç›¸ä¼¼åº¦çŸ©é˜µ
        velocity_matrix = np.zeros((len(detections), len(tracks)))
        
        # ========== æ–¹æ¡ˆ3: å¯é€‰çš„è¶‹åŠ¿ç›¸ä¼¼åº¦çŸ©é˜µ ==========
        if self.use_velocity_trend:
            trend_matrix = np.zeros((len(detections), len(tracks)))
        
        for d, det in enumerate(detections):
            # ä¼°è®¡æ£€æµ‹é€Ÿåº¦
            det_vel = estimate_detection_velocity(det, self.detection_history, self.current_frame)
            
            for t, trk in enumerate(tracks):
                # ========== æ–¹æ¡ˆB: å½“å‰é€Ÿåº¦ç›¸ä¼¼åº¦ ==========
                if self.use_smooth_velocity:
                    # æ–¹æ¡ˆ3: ä½¿ç”¨å¹³æ»‘é€Ÿåº¦ (é™ä½å™ªå£°)
                    velocity_matrix[d, t] = compute_smooth_velocity_similarity(
                        trk, det_vel, window=self.velocity_smooth_window
                    )
                else:
                    # æ–¹æ¡ˆB: ä½¿ç”¨å½“å‰é€Ÿåº¦
                    trk_vel = get_velocity(trk)
                    velocity_matrix[d, t] = compute_velocity_similarity(trk_vel, det_vel)
                
                # ========== æ–¹æ¡ˆ3: è¶‹åŠ¿ç›¸ä¼¼åº¦ (è€ƒè™‘åŠ é€Ÿåº¦) ==========
                if self.use_velocity_trend:
                    trend_matrix[d, t] = compute_velocity_trend_similarity(
                        trk, det_vel, use_smooth=True
                    )
        
        # ========== æ–¹æ¡ˆ3: èåˆå½“å‰é€Ÿåº¦å’Œè¶‹åŠ¿ ==========
        if self.use_velocity_trend:
            # èåˆ: (1-w)*å½“å‰é€Ÿåº¦ + w*è¶‹åŠ¿
            velocity_matrix = (
                (1 - self.trend_weight) * velocity_matrix + 
                self.trend_weight * trend_matrix
            )
        
        # 2. è®¡ç®—ä½ç½®é¢„æµ‹ç›¸ä¼¼åº¦ (åŸºäºé€Ÿåº¦é¢„æµ‹)
        position_matrix = np.zeros((len(detections), len(tracks)))
        weight_matrix = np.zeros((len(detections), len(tracks)))  # æ¯å¯¹çš„è‡ªé€‚åº”æƒé‡
        
        for d, det in enumerate(detections):
            for t, trk in enumerate(tracks):
                # ========== æ–¹æ¡ˆ3: ä½¿ç”¨è¶‹åŠ¿é¢„æµ‹ä½ç½® (æ”¹è¿›) ==========
                if self.use_velocity_trend and hasattr(trk, 'get_velocity_trend'):
                    # ä½¿ç”¨å¹³æ»‘é€Ÿåº¦å’Œè¶‹åŠ¿
                    if self.use_smooth_velocity:
                        trk_vel = trk.get_average_velocity(window=self.velocity_smooth_window)
                    else:
                        trk_vel = get_velocity(trk)
                    
                    # è·å–é€Ÿåº¦è¶‹åŠ¿
                    if hasattr(trk, 'get_smooth_velocity_trend'):
                        trk_trend = trk.get_smooth_velocity_trend(window=self.velocity_smooth_window)
                    else:
                        trk_trend = trk.get_velocity_trend()
                    
                    # é¢„æµ‹é€Ÿåº¦ (è€ƒè™‘åŠ é€Ÿåº¦)
                    predicted_vel = trk_vel + trk_trend * 0.1
                    predicted_pos = trk.pose[:3] + predicted_vel[:3] * 0.1
                else:
                    # ========== æ–¹æ¡ˆB: ç®€å•çº¿æ€§é¢„æµ‹ ==========
                    trk_vel = get_velocity(trk)
                    predicted_pos = trk.pose[:3] + trk_vel[:3] * 0.1  # å‡è®¾dt=0.1s
                
                # è®¡ç®—é¢„æµ‹ä½ç½®ä¸æ£€æµ‹ä½ç½®çš„è·ç¦»
                dist = np.linalg.norm(det.bbox[:3] - predicted_pos)
                
                # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (è·ç¦»è¶Šå°,ç›¸ä¼¼åº¦è¶Šé«˜)
                position_matrix[d, t] = np.exp(-dist / 5.0)  # 5ç±³è¡°å‡
                
                # è·å–è¯¥è½¨è¿¹çš„è‡ªé€‚åº”æƒé‡
                weight_matrix[d, t] = self._get_adaptive_velocity_weight(trk)
        
        # 3. èåˆé€Ÿåº¦å’Œä½ç½®ç›¸ä¼¼åº¦ (ä½¿ç”¨è‡ªé€‚åº”æƒé‡)
        combined_matrix = np.zeros((len(detections), len(tracks)))
        for d in range(len(detections)):
            for t in range(len(tracks)):
                w = weight_matrix[d, t]
                combined_matrix[d, t] = (
                    w * velocity_matrix[d, t] + 
                    (1 - w) * position_matrix[d, t]
                )
        
        # 4. åŒˆç‰™åˆ©ç®—æ³•æ±‚è§£
        cost_matrix = -combined_matrix  # è½¬ä¸ºä»£ä»·çŸ©é˜µ
        matched_indices = linear_assignment(cost_matrix)
        
        # 5. è¿‡æ»¤ä½ç›¸ä¼¼åº¦åŒ¹é…
        matches = []
        unmatched_dets = []
        unmatched_trks = []
        
        for d in range(len(detections)):
            if d not in matched_indices[:, 0]:
                unmatched_dets.append(d)
        
        for t in range(len(tracks)):
            if t not in matched_indices[:, 1]:
                unmatched_trks.append(t)
        
        for d, t in matched_indices:
            if combined_matrix[d, t] < self.velocity_threshold:
                # ç›¸ä¼¼åº¦å¤ªä½,æ‹’ç»åŒ¹é…
                unmatched_dets.append(d)
                unmatched_trks.append(t)
            else:
                matches.append([d, t])
        
        return matches, unmatched_dets, unmatched_trks
    
    def _get_adaptive_velocity_weight(self, track):
        """
        æ ¹æ®è½¨è¿¹é€Ÿåº¦å¤§å°åŠ¨æ€è°ƒæ•´é€Ÿåº¦æƒé‡ (æ–¹æ¡ˆB: è½»é‡çº§ä¼˜åŒ–)
        
        Args:
            track: è½¨è¿¹å¯¹è±¡
        
        Returns:
            weight: è‡ªé€‚åº”é€Ÿåº¦æƒé‡
        """
        if not self.adaptive_weight:
            return self.velocity_weight
        
        # è·å–è½¨è¿¹é€Ÿåº¦
        velocity = get_velocity(track)
        speed = np.linalg.norm(velocity)
        
        # æ ¹æ®é€Ÿåº¦å¤§å°è°ƒæ•´æƒé‡
        if speed > 15.0:  # é«˜é€Ÿåœºæ™¯ (>54 km/h)
            weight = 0.7  # æé«˜é€Ÿåº¦æƒé‡ï¼Œé€Ÿåº¦ä¿¡æ¯æ›´å¯é 
            # print(f"[è‡ªé€‚åº”æƒé‡] é«˜é€Ÿè½¨è¿¹ {track.id}: {speed:.2f} m/s, æƒé‡={weight}")
        elif speed < 3.0:  # ä½é€Ÿåœºæ™¯ (<10.8 km/h)
            weight = 0.3  # é™ä½é€Ÿåº¦æƒé‡ï¼Œä½ç½®ä¿¡æ¯æ›´é‡è¦
            # print(f"[è‡ªé€‚åº”æƒé‡] ä½é€Ÿè½¨è¿¹ {track.id}: {speed:.2f} m/s, æƒé‡={weight}")
        else:  # ä¸­é€Ÿåœºæ™¯ (3-15 m/s)
            weight = 0.5  # é»˜è®¤æƒé‡
        
        return weight
    
    def _update_detection_history(self, detections):
        """
        æ›´æ–°æ£€æµ‹å†å² (ç”¨äºé€Ÿåº¦ä¼°è®¡)
        """
        self.detection_history[self.current_frame] = detections
        
        # åªä¿ç•™æœ€è¿‘5å¸§
        if len(self.detection_history) > 5:
            oldest_frame = min(self.detection_history.keys())
            del self.detection_history[oldest_frame]

    def _initiate_track_3d(self, detection,emb=None):
        self.kf_3d = KalmanBoxTracker(detection.bbox)
        self.additional_info = detection.additional_info
        pose = np.concatenate(self.kf_3d.kf.x[:7], axis=0)
        self.tracks_3d.append(Track_3D(pose, self.kf_3d, self.track_id_3d, self.n_init, self.max_age,self.additional_info,emb))
        self.track_id_3d += 2

    def _initiate_track_2d(self, detection,emb):
        mean, covariance = self.kf_2d.initiate(detection.to_xyah())
        self.tracks_2d.append(Track_2D(mean, covariance, self.track_id_2d, self.n_init, self.max_age,emb))
        self.track_id_2d += 2