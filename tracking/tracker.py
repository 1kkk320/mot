import numpy as np
import math
import time
from tracking import kalman_filter_2d
from tracking.cost_function import (iou_batch, get_velocity, compute_velocity_similarity, 
                                     estimate_detection_velocity, compute_velocity_trend_similarity,
                                     compute_smooth_velocity_similarity, compute_adaptive_weight_linear)
from tracking.matching import associate_detections_to_trackers_fusion, associate_2D_to_3D_tracking, linear_assignment,associate_detections_to_tracks
from tracking.track_2d import Track_2D
from tracking.kalman_fileter_3d import  KalmanBoxTracker
from tracking.track_3d import Track_3D
from trackers.ocsort_embedding.embedding import EmbeddingComputer
from tracking.matching import compute_aw_new_metric
from tracking.angle_feature import AngleFeatureConfig, compute_angle_similarity_matrix
from tracking.multi_frame_backtrack import (MultiFrameBacktrackConfig, 
                                           multi_frame_backtrack_association,
                                           process_multi_frame_matches)


class Tracker:
    def __init__(self, max_age, n_init, embeddiong_off=False, aw_off=False, grid_off=False,app_off=True,**kwargs):
        self.max_age = max_age
        self.n_init = n_init
        self.tracks_3d = []
        self.tracks_2d = []
        self.track_id_3d = 0   # The id of 3D track is represented by an even number.3dè½¨è¿¹idç”±å¶æ•°è¡¨ç¤º
        self.track_id_2d = 1   # The id of 2D track is represented by an odd number.2dè½¨è¿¹IDä¸ºå¥‡æ•°
        self.unmatch_tracks_3d = []
        self.kf_2d = kalman_filter_2d.KalmanFilter()
        self.embedding_off = embeddiong_off
        self.aw_off = aw_off
        self.det_thresh = 0.2
        self.alpha_fixed_emb = 0.9
        self.grid_off = grid_off
        self.app_off = app_off
        self.mot_off = False
        self.embedder = EmbeddingComputer(grid_off=self.grid_off)
        self.appearance_weight_level1 = kwargs.get('appearance_weight_level1', 0.15)
        
        # ========== é€Ÿåº¦è‡ªé€‚åº”å›æº¯å…³è”å‚æ•° ==========
        self.velocity_backtrack_enabled = True   # å¯ç”¨é€Ÿåº¦å›æº¯ï¼ˆåˆ›æ–°å¼€å¯ï¼‰
        self.velocity_threshold = 0.6            # é€Ÿåº¦ç›¸ä¼¼åº¦é˜ˆå€¼
        self.velocity_weight = 0.5               # é»˜è®¤é€Ÿåº¦æƒé‡ (0.5è¡¨ç¤ºé€Ÿåº¦å’Œä½ç½®å„å 50%)
        self.adaptive_weight = True              # å¯ç”¨è‡ªé€‚åº”é€Ÿåº¦æƒé‡ (æ–¹æ¡ˆB)
        self.detection_history = {}              # å†å²æ£€æµ‹ç¼“å­˜ {frame_id: detections}
        self.current_frame = 0                   # å½“å‰å¸§è®¡æ•°
        self.velocity_weight_vmax = 10.0
        self.adaptive_threshold_low = 0.55
        self.adaptive_threshold_mid = 0.60
        self.adaptive_threshold_high = 0.70
        
        # ========== æ–¹æ¡ˆ3: å¤šå¸§å›æº¯å‚æ•° ==========
        self.use_velocity_trend = True           # å¯ç”¨é€Ÿåº¦è¶‹åŠ¿ï¼ˆåˆ›æ–°å¼€å¯ï¼‰
        self.use_smooth_velocity = True          # å¯ç”¨é€Ÿåº¦å¹³æ»‘ï¼ˆåˆ›æ–°å¼€å¯ï¼‰
        self.velocity_smooth_window = 3          # é€Ÿåº¦å¹³æ»‘çª—å£å¤§å°
        self.trend_weight = 0.3                  # è¶‹åŠ¿æƒé‡ (0.3è¡¨ç¤º30%è¶‹åŠ¿ + 70%å½“å‰é€Ÿåº¦)
        
        # ========== å¤šå¸§å…³è”é…ç½® ==========
        self.multi_frame_config = MultiFrameBacktrackConfig()
        self.multi_frame_config.enable_multi_frame_backtrack = False  # âŒ ç¦ç”¨å¤šå¸§å…³è”
        self.multi_frame_config.min_backtrack_age = 3
        self.multi_frame_config.max_backtrack_age = 15
        self.multi_frame_config.lambda_decay = 0.05
        self.multi_frame_config.cost_threshold = -0.3
        self.multi_frame_config.verbose = False
        self.enable_angle_in_level1 = True       # å¯ç”¨è§’åº¦ç‰¹å¾ï¼ˆåˆ›æ–°å¼€å¯ï¼‰
        self.enable_angle_gate_in_backtrack = False
        self.angle_level1_weight = 0.25
        self.angle_level1_method = 'gaussian'
        self.angle_level1_sigma = 0.35
        self.angle_level1_gate_threshold = math.radians(45)
        self.angle_backtrack_method = 'gaussian'
        self.angle_backtrack_sigma = 0.30
        self.angle_backtrack_gate_threshold = math.radians(60)
        self.angle_config = AngleFeatureConfig()
        self.angle_config.enable_angle_feature = self.enable_angle_in_level1
        self.angle_config.angle_cost_method = self.angle_level1_method
        self.angle_config.angle_cost_sigma = self.angle_level1_sigma
        self.angle_config.enable_angle_gate = True   # å¯ç”¨è§’åº¦é—¨æ§ï¼ˆåˆ›æ–°å¼€å¯ï¼‰
        self.angle_config.angle_gate_threshold = self.angle_level1_gate_threshold
        self.angle_config.angle_weight = self.angle_level1_weight
        self.angle_config.verbose = False
        self.backtrack_angle_gate_verbose = True
        self.t_L1 = 0.0
        self.t_L15 = 0.0
        self.t_L2 = 0.0
        self.t_L3 = 0.0
        self.t_L4 = 0.0

    def predict_3d(self):
        # print(self.tracks_3d)
        for track in self.tracks_3d:
            # print(track)
            track.predict_3d(track.kf_3d)

    def predict_2d(self):
        # print(self.tracks_2d)
        for track in self.tracks_2d:
            # print(track)
            track.predict_2d(self.kf_2d)

    def update(self, detection_3D_fusion, detection_3D_only, detection_3Dto2D_only, detection_2D_only, calib_file, img, detection_2D_only_conf, detection_3D_fusion_conf, iou_threshold):

        # æ¢å¤ï¼šåˆå§‹åŒ–å ä½åµŒå…¥ï¼Œéšååœ¨æœªå…³é—­embeddingæ—¶å†è®¡ç®—çœŸå®ç‰¹å¾
        dets_3D_fusion_embs = np.ones((len(detection_3D_fusion), 1))
        dets_3D_only_embs = np.ones((len(detection_3D_only), 1))
        dets_2D_only_embs = np.ones((len(detection_2D_only), 1))

        det_3D_fusion_bboxs = [det_3d_f.additional_info[2:6] for det_3d_f in detection_3D_fusion]
        dets_fusion_alpha = None
        dets_2d_only_alpha = None
        # æ¢å¤ï¼šä¸€çº§ä½¿ç”¨å¤–è§‚ï¼ˆè‹¥æœªå…³é—­embeddingï¼‰
        use_app_L1 = True
        if use_app_L1 and not self.embedding_off and len(detection_3D_fusion) > 0:
            dets_3D_fusion_embs = self.embedder.compute_embedding(img, det_3D_fusion_bboxs)
        if len(detection_3D_fusion_conf) != 0:
            trust_fusion = np.asarray([(i - self.det_thresh) / (1 - self.det_thresh) for i in detection_3D_fusion_conf])
        else:
            trust_fusion = np.asarray(list())
        if len(detection_2D_only_conf) != 0:
            trust_2D_only = np.asarray([(i - self.det_thresh) / (1 - self.det_thresh) for i in detection_2D_only_conf])
        else:
            trust_2D_only = np.asarray(list())
        af = self.alpha_fixed_emb
        if len(trust_fusion) != 0:
            dets_fusion_alpha = af + (1 - af) * (1 - trust_fusion)
        if len(trust_2D_only) != 0:
            dets_2d_only_alpha = af + (1 - af) * (1 - trust_2D_only)

        # æ›´æ–°å¸§è®¡æ•° (åœ¨å…³è”ä¹‹å‰)
        self.current_frame += 1

        # 1st Level of Association
        t0 = time.time()
        matched_fusion_idx, unmatched_dets_fusion_idx, unmatched_trks_fusion_idx = associate_detections_to_trackers_fusion(
            detection_3D_fusion, self.tracks_3d, self.aw_off, self.grid_off, self.mot_off, iou_threshold,
            det_embs=dets_3D_fusion_embs, det_app=False, angle_config=self.angle_config,
            enable_angle=self.enable_angle_in_level1, appearance_weight=self.appearance_weight_level1)
        for detection_idx, track_idx in matched_fusion_idx:
            self.tracks_3d[track_idx].update_3d(detection_3D_fusion[detection_idx])
            if use_app_L1 and dets_3D_fusion_embs.shape[0] > detection_idx:
                if dets_fusion_alpha is not None and dets_fusion_alpha.shape[0] > detection_idx:
                    self.tracks_3d[track_idx].update_emb(dets_3D_fusion_embs[detection_idx], alpha=dets_fusion_alpha[detection_idx])
                else:
                    self.tracks_3d[track_idx].update_emb(dets_3D_fusion_embs[detection_idx], alpha=self.alpha_fixed_emb)
            self.tracks_3d[track_idx].state = 2
            self.tracks_3d[track_idx].fusion_time_update = 0
        self.t_L1 += time.time() - t0
        # ========== Level 1.5: é€Ÿåº¦è‡ªé€‚åº”å›æº¯å…³è” ==========
        # åœ¨å¤„ç†æœªåŒ¹é…ä¹‹å‰,å…ˆå°è¯•é€Ÿåº¦å›æº¯
        if self.velocity_backtrack_enabled and \
           len(unmatched_dets_fusion_idx) > 0 and \
           len(unmatched_trks_fusion_idx) > 0:
            t1 = time.time()
            print(f"[é€Ÿåº¦å›æº¯] æœªåŒ¹é…æ£€æµ‹: {len(unmatched_dets_fusion_idx)}, "
                  f"æœªåŒ¹é…è½¨è¿¹: {len(unmatched_trks_fusion_idx)}")
            
            # æå–æœªåŒ¹é…çš„æ£€æµ‹å’Œè½¨è¿¹
            unmatched_dets = [detection_3D_fusion[i] for i in unmatched_dets_fusion_idx]
            unmatched_trks = [self.tracks_3d[i] for i in unmatched_trks_fusion_idx]
            
            # é€Ÿåº¦å›æº¯å…³è”
            velocity_matched, velocity_unmatched_dets, velocity_unmatched_trks = \
                self._velocity_backtrack_association(
                    unmatched_dets, 
                    unmatched_trks,
                    dets_3D_fusion_embs,
                    unmatched_dets_fusion_idx
                )
            
            # æ›´æ–°åŒ¹é…æˆåŠŸçš„è½¨è¿¹
            for det_idx, trk_idx in velocity_matched:
                original_det_idx = unmatched_dets_fusion_idx[det_idx]
                original_trk_idx = unmatched_trks_fusion_idx[trk_idx]
                
                self.tracks_3d[original_trk_idx].update_3d(
                    detection_3D_fusion[original_det_idx]
                )
                if not self.app_off:
                    self.tracks_3d[original_trk_idx].update_emb(
                        dets_3D_fusion_embs[original_det_idx]
                    )
                self.tracks_3d[original_trk_idx].state = 2
                self.tracks_3d[original_trk_idx].fusion_time_update = 0
                
                print(f"[é€Ÿåº¦å›æº¯] âœ… æˆåŠŸåŒ¹é…: æ£€æµ‹{original_det_idx} â†” è½¨è¿¹{original_trk_idx}")
            
            # æ›´æ–°æœªåŒ¹é…åˆ—è¡¨ (åªä¿ç•™çœŸæ­£æœªåŒ¹é…çš„)
            unmatched_dets_fusion_idx = [
                unmatched_dets_fusion_idx[i] for i in velocity_unmatched_dets
            ]
            unmatched_trks_fusion_idx = [
                unmatched_trks_fusion_idx[i] for i in velocity_unmatched_trks
            ]
            
            if len(velocity_matched) > 0:
                print(f"[é€Ÿåº¦å›æº¯] ğŸ“Š æœ¬å¸§åŒ¹é…æˆåŠŸ: {len(velocity_matched)}å¯¹")
            self.t_L15 += time.time() - t1
                        
        # ========== å¤šå¸§å…³è” (Level 2.5) ==========
        # åœ¨é€Ÿåº¦å›æº¯å…³è”åï¼Œå¯¹ä»æœªåŒ¹é…çš„è½¨è¿¹è¿›è¡Œå¤šå¸§å†å²å…³è”
        if self.multi_frame_config.enable_multi_frame_backtrack and \
           len(unmatched_dets_fusion_idx) > 0 and \
           len(unmatched_trks_fusion_idx) > 0:
            
            print(f"[å¤šå¸§å…³è”] å°è¯•å¤šå¸§å›æº¯: æœªåŒ¹é…æ£€æµ‹{len(unmatched_dets_fusion_idx)}, "
                  f"æœªåŒ¹é…è½¨è¿¹{len(unmatched_trks_fusion_idx)}")
            
            # æå–æœªåŒ¹é…çš„æ£€æµ‹å’Œè½¨è¿¹
            unmatched_dets_mf = [detection_3D_fusion[i] for i in unmatched_dets_fusion_idx]
            unmatched_trks_mf = [self.tracks_3d[i] for i in unmatched_trks_fusion_idx]
            
            # æ‰§è¡Œå¤šå¸§å›æº¯å…³è”
            multi_frame_matches = multi_frame_backtrack_association(
                unmatched_trks_mf,
                self.detection_history,
                self.current_frame,
                self.multi_frame_config
            )
            
            # å¤„ç†å¤šå¸§åŒ¹é…ç»“æœ
            if len(multi_frame_matches) > 0:
                updated_tracks = process_multi_frame_matches(
                    multi_frame_matches,
                    verbose=self.multi_frame_config.verbose
                )
                
                # æ›´æ–°åµŒå…¥ç‰¹å¾
                for track in updated_tracks:
                    if not self.app_off:
                        # æŸ¥æ‰¾å¯¹åº”çš„æ£€æµ‹åµŒå…¥
                        for i, det in enumerate(detection_3D_fusion):
                            if np.allclose(det.bbox[:3], track.pose[:3], atol=0.1):
                                track.update_emb(dets_3D_fusion_embs[i])
                                break
                    
                    # ä»æœªåŒ¹é…åˆ—è¡¨ä¸­ç§»é™¤å·²åŒ¹é…çš„è½¨è¿¹
                    # åœ¨self.tracks_3dä¸­æ‰¾åˆ°è¯¥è½¨è¿¹çš„ç´¢å¼•
                    for idx, t in enumerate(self.tracks_3d):
                        if t.track_id_3d == track.track_id_3d:
                            if idx in unmatched_trks_fusion_idx:
                                unmatched_trks_fusion_idx.remove(idx)
                            break
                
                print(f"[å¤šå¸§å…³è”] âœ… æˆåŠŸåŒ¹é…: {len(multi_frame_matches)}å¯¹")
            else:
                print(f"[å¤šå¸§å…³è”] âŒ æœªæ‰¾åˆ°åŒ¹é…")  
        
        # å¤„ç†æœ€ç»ˆæœªåŒ¹é…çš„è½¨è¿¹å’Œæ£€æµ‹
        for track_idx in unmatched_trks_fusion_idx:
            self.tracks_3d[track_idx].fusion_time_update += 1
            self.tracks_3d[track_idx].mark_missed()
        for detection_idx in unmatched_dets_fusion_idx:
            self._initiate_track_3d(detection_3D_fusion[detection_idx], dets_3D_fusion_embs[detection_idx])

        #  2nd Level of Association
        self.unmatch_tracks_3d1 = [t for t in self.tracks_3d if t.time_since_update > 0]
        t2 = time.time()
        matched_only_idx, unmatched_dets_only_idx, _ = associate_detections_to_trackers_fusion(
            detection_3D_only, self.unmatch_tracks_3d1, self.aw_off, self.grid_off, self.mot_off, iou_threshold,
            det_embs=dets_3D_only_embs, det_app=self.app_off)
        index_to_delete = []
        for detection_idx, track_idx in matched_only_idx:
            for index, t in enumerate(self.tracks_3d):
                if t.track_id_3d == self.unmatch_tracks_3d1[track_idx].track_id_3d:
                    t.update_3d(detection_3D_only[detection_idx])
                    if not self.app_off:
                        t.update_emb(dets_3D_only_embs[detection_idx])
                    index_to_delete.append(track_idx)
                    break
        self.unmatch_tracks_3d1 = [self.unmatch_tracks_3d1[i] for i in range(len(self.unmatch_tracks_3d1)) if i not in index_to_delete]
        for detection_idx in unmatched_dets_only_idx:
            self._initiate_track_3d(detection_3D_only[detection_idx], dets_3D_only_embs[detection_idx])
        self.unmatch_tracks_3d2 = [t for t in self.tracks_3d if t.time_since_update == 0 and t.hits == 1 ]
        self.unmatch_tracks_3d = self.unmatch_tracks_3d1 + self.unmatch_tracks_3d2
        self.t_L2 += time.time() - t2

        # 3rd Level of Association
        t3 = time.time()
        matched, unmatch_trks, unmatch_dets = associate_detections_to_tracks(self.tracks_2d, detection_2D_only, iou_threshold, self.aw_off,self.grid_off,self.mot_off, det_embs=dets_2D_only_embs, det_app = self.app_off)
        for track_idx, detection_idx in matched:
            self.tracks_2d[track_idx].update_2d(self.kf_2d, detection_2D_only[detection_idx])
            if not self.app_off:
                self.tracks_2d[track_idx].update_emb(dets_2D_only_embs[detection_idx])
        for track_idx in unmatch_trks:
            self.tracks_2d[track_idx].mark_missed()
        for detection_idx in unmatch_dets:
            self._initiate_track_2d(detection_2D_only[detection_idx], dets_2D_only_embs[detection_idx])
        self.tracks_2d = [t for t in self.tracks_2d if not t.is_deleted()]
        self.t_L3 += time.time() - t3

        #  4th Level of Association
        t4 = time.time()
        matched_track_2d, unmatch_tracks_2d = associate_2D_to_3D_tracking(self.tracks_2d, self.unmatch_tracks_3d, calib_file, iou_threshold)
        index_to_delete2 = []
        for track_idx_2d, track_idx_3d in matched_track_2d:
            for i in range(len(self.tracks_3d)):
                if self.tracks_3d[i].track_id_3d == self.unmatch_tracks_3d[track_idx_3d].track_id_3d:
                    self.tracks_3d[i].age = self.tracks_2d[track_idx_2d].age + 1
                    if self.tracks_3d[i].track_id_3d % 2 ==0:
                        new_id = self.tracks_2d[track_idx_2d].track_id_2d
                        # ========== ä¿®å¤: æ£€æŸ¥IDå”¯ä¸€æ€§ ==========
                        existing_ids = [t.track_id_3d for t in self.tracks_3d if t != self.tracks_3d[i]]
                        if new_id not in existing_ids:
                            # print(self.tracks_3d[i].track_id_3d,self.tracks_2d[track_idx_2d].track_id_2d)
                            self.tracks_3d[i].track_id_3d = new_id
                            # print("recite:",self.tracks_3d[i].track_id_3d)
                        else:
                            print(f"âš ï¸ è·³è¿‡IDä¿®æ”¹: {new_id} å·²å­˜åœ¨äºtracks_3dä¸­")
                        # ========================================
                    self.tracks_3d[i].time_since_update = 0
                    if self.tracks_2d[track_idx_2d].hits >= 2:
                        self.tracks_3d[i].hits = self.tracks_2d[track_idx_2d].hits + 1
                    else:
                        self.tracks_3d[i].hits += 1
                    self.tracks_3d[i].state_update()
            index_to_delete2.append(track_idx_2d)
        self.tracks_2d = [self.tracks_2d[i] for i in range(len(self.tracks_2d)) if i not in index_to_delete2]
        self.tracks_3d = [t for t in self.tracks_3d if not t.is_deleted()]
        self.t_L4 += time.time() - t4
        
        # ========== DEBUG: æ£€æŸ¥é‡å¤ID ==========
        track_ids = [t.track_id_3d for t in self.tracks_3d if t.is_confirmed()]
        if len(track_ids) != len(set(track_ids)):
            from collections import Counter
            duplicates = [id for id, count in Counter(track_ids).items() if count > 1]
            print(f"âŒ è­¦å‘Šï¼šå‘ç°é‡å¤çš„è½¨è¿¹ID: {duplicates}")
            print(f"   æ‰€æœ‰ID: {track_ids}")
            print(f"   å¸§å·: {self.current_frame}")
        # ========================================
        
        # æ›´æ–°æ£€æµ‹å†å² (å¸§è®¡æ•°å·²åœ¨å‡½æ•°å¼€å§‹æ—¶æ›´æ–°)
        self._update_detection_history(detection_3D_fusion)

    def _velocity_backtrack_association(self, detections, tracks, det_embs, det_indices):
        """
        å¤šå±‚çº§å›æº¯å…³è” - æ ¹æ®è½¨è¿¹å¹´é¾„åº”ç”¨ä¸åŒçš„å‚æ•°
        
        Args:
            detections: æœªåŒ¹é…çš„æ£€æµ‹åˆ—è¡¨
            tracks: æœªåŒ¹é…çš„è½¨è¿¹åˆ—è¡¨
            det_embs: æ£€æµ‹çš„åµŒå…¥ç‰¹å¾
            det_indices: æ£€æµ‹åœ¨åŸåˆ—è¡¨ä¸­çš„ç´¢å¼•
        
        Returns:
            matched: åŒ¹é…çš„ç´¢å¼•å¯¹ [(det_idx, trk_idx), ...]
            unmatched_dets: æœªåŒ¹é…çš„æ£€æµ‹ç´¢å¼•
            unmatched_trks: æœªåŒ¹é…çš„è½¨è¿¹ç´¢å¼•
        """
        if len(detections) == 0 or len(tracks) == 0:
            return [], list(range(len(detections))), list(range(len(tracks)))
        
        # ========== åœºæ™¯è‡ªé€‚åº”å‚æ•°é…ç½® ==========
        # è¯†åˆ«åœºæ™¯ç±»å‹å¹¶è·å–è‡ªé€‚åº”å‚æ•°
        scene_type = self._identify_scene_type(detections, tracks)
        adaptive_config = self._get_adaptive_backtrack_config(scene_type)
        
        # å¦‚æœåœºæ™¯ä¸é€‚åˆå›æº¯ï¼Œç›´æ¥è¿”å›
        if not adaptive_config['enable_backtrack']:
            return [], list(range(len(detections))), list(range(len(tracks)))
        
        # ä½¿ç”¨è‡ªé€‚åº”å‚æ•°
        velocity_weight = adaptive_config['velocity_weight']
        position_weight = adaptive_config['position_weight']
        velocity_threshold = adaptive_config['velocity_threshold']
        max_backtrack_age = adaptive_config['max_backtrack_age']
        
        # 1. è®¡ç®—é€Ÿåº¦ç›¸ä¼¼åº¦çŸ©é˜µ
        velocity_matrix = np.zeros((len(detections), len(tracks)))
        
        if self.use_velocity_trend:
            trend_matrix = np.zeros((len(detections), len(tracks)))
        
        for d, det in enumerate(detections):
            det_vel = estimate_detection_velocity(det, self.detection_history, self.current_frame)
            
            for t, trk in enumerate(tracks):
                if self.use_smooth_velocity:
                    velocity_matrix[d, t] = compute_smooth_velocity_similarity(
                        trk, det_vel, window=self.velocity_smooth_window
                    )
                else:
                    trk_vel = get_velocity(trk)
                    velocity_matrix[d, t] = compute_velocity_similarity(trk_vel, det_vel)
                
                if self.use_velocity_trend:
                    trend_matrix[d, t] = compute_velocity_trend_similarity(
                        trk, det_vel, use_smooth=True
                    )
        
        if self.use_velocity_trend:
            velocity_matrix = (
                (1 - self.trend_weight) * velocity_matrix + 
                self.trend_weight * trend_matrix
            )
        
        # 2. è®¡ç®—ä½ç½®é¢„æµ‹ç›¸ä¼¼åº¦ (åŸºäºé€Ÿåº¦é¢„æµ‹)
        position_matrix = np.zeros((len(detections), len(tracks)))
        
        for d, det in enumerate(detections):
            for t, trk in enumerate(tracks):
                if self.use_velocity_trend and hasattr(trk, 'get_velocity_trend'):
                    if self.use_smooth_velocity:
                        trk_vel = trk.get_average_velocity(window=self.velocity_smooth_window)
                    else:
                        trk_vel = get_velocity(trk)
                    
                    if hasattr(trk, 'get_smooth_velocity_trend'):
                        trk_trend = trk.get_smooth_velocity_trend(window=self.velocity_smooth_window)
                    else:
                        trk_trend = trk.get_velocity_trend()
                    
                    dt = 0.1
                    acceleration = self._compute_acceleration(trk)
                    predicted_pos = (
                        trk.pose[:3] + 
                        trk_vel[:3] * dt + 
                        0.5 * acceleration[:3] * dt**2
                    )
                else:
                    trk_vel = get_velocity(trk)
                    predicted_pos = trk.pose[:3] + trk_vel[:3] * 0.1
                
                dist = np.linalg.norm(det.bbox[:3] - predicted_pos)
                position_matrix[d, t] = np.exp(-dist / 5.0)
        
        
        combined_matrix = np.zeros((len(detections), len(tracks)))
        track_weights = []
        for trk in tracks:
            trk_vel = get_velocity(trk)
            w_vel_t, w_pos_t = compute_adaptive_weight_linear(trk_vel, self.velocity_weight_vmax)
            track_weights.append((w_vel_t, w_pos_t))
        for d in range(len(detections)):
            for t in range(len(tracks)):
                w_vel_t, w_pos_t = track_weights[t]
                combined_matrix[d, t] = (
                    w_vel_t * velocity_matrix[d, t] +
                    w_pos_t * position_matrix[d, t]
                )
        
        if self.enable_angle_gate_in_backtrack:
            track_angles = np.array([trk.pose[6] if len(trk.pose) >= 7 else 0.0 for trk in tracks])
            det_angles = np.array([det.bbox[6] if len(det.bbox) >= 7 else 0.0 for det in detections])
            _, gate_mask = compute_angle_similarity_matrix(
                track_angles,
                det_angles,
                method=self.angle_backtrack_method,
                sigma=self.angle_backtrack_sigma,
                gate_threshold=self.angle_backtrack_gate_threshold
            )
            gate_mask_T = gate_mask.T
            if getattr(self, 'backtrack_angle_gate_verbose', False):
                n_total_pairs = int(gate_mask.size)
                n_rejected = int((~gate_mask).sum())
                ratio = (n_rejected / n_total_pairs * 100.0) if n_total_pairs > 0 else 0.0
                print(f"[å›æº¯è§’åº¦é—¨æ§] æ‹’ç» {n_rejected}/{n_total_pairs} å¯¹ ({ratio:.2f}%)")
            combined_matrix[~gate_mask_T] = -1e9
        
        # 4. åŒˆç‰™åˆ©ç®—æ³•æ±‚è§£
        cost_matrix = -combined_matrix
        matched_indices = linear_assignment(cost_matrix)
        
        # 5. è¿‡æ»¤ä½ç›¸ä¼¼åº¦åŒ¹é…
        matches = []
        unmatched_dets = []
        unmatched_trks = []
        
        for d in range(len(detections)):
            if d not in matched_indices[:, 0]:
                unmatched_dets.append(d)
        
        for t in range(len(tracks)):
            if t not in matched_indices[:, 1]:
                unmatched_trks.append(t)
        
        for d, t in matched_indices:
            if combined_matrix[d, t] < velocity_threshold:
                unmatched_dets.append(d)
                unmatched_trks.append(t)
            else:
                matches.append([d, t])
        
        return matches, unmatched_dets, unmatched_trks
    
    def _get_adaptive_velocity_weight(self, track):
        """
        æ ¹æ®è½¨è¿¹é€Ÿåº¦å¤§å°åŠ¨æ€è°ƒæ•´é€Ÿåº¦æƒé‡ (æ–¹æ¡ˆB: è½»é‡çº§ä¼˜åŒ–)
        
        Args:
            track: è½¨è¿¹å¯¹è±¡
        
        Returns:
            weight: è‡ªé€‚åº”é€Ÿåº¦æƒé‡
        """
        if not self.adaptive_weight:
            return self.velocity_weight
        
        # è·å–è½¨è¿¹é€Ÿåº¦
        velocity = get_velocity(track)
        speed = np.linalg.norm(velocity)
        
        # æ ¹æ®é€Ÿåº¦å¤§å°è°ƒæ•´æƒé‡
        if speed > 15.0:  # é«˜é€Ÿåœºæ™¯ (>54 km/h)
            weight = 0.7  # æé«˜é€Ÿåº¦æƒé‡ï¼Œé€Ÿåº¦ä¿¡æ¯æ›´å¯é 
            # print(f"[è‡ªé€‚åº”æƒé‡] é«˜é€Ÿè½¨è¿¹ {track.id}: {speed:.2f} m/s, æƒé‡={weight}")
        elif speed < 3.0:  # ä½é€Ÿåœºæ™¯ (<10.8 km/h)
            weight = 0.3  # é™ä½é€Ÿåº¦æƒé‡ï¼Œä½ç½®ä¿¡æ¯æ›´é‡è¦
            # print(f"[è‡ªé€‚åº”æƒé‡] ä½é€Ÿè½¨è¿¹ {track.id}: {speed:.2f} m/s, æƒé‡={weight}")
        else:  # ä¸­é€Ÿåœºæ™¯ (3-15 m/s)
            weight = 0.5  # é»˜è®¤æƒé‡
        
        return weight
    
    def _update_detection_history(self, detections):
        """
        æ›´æ–°æ£€æµ‹å†å² (ç”¨äºé€Ÿåº¦ä¼°è®¡)
        """
        self.detection_history[self.current_frame] = detections
        
        # åªä¿ç•™æœ€è¿‘5å¸§
        if len(self.detection_history) > 5:
            oldest_frame = min(self.detection_history.keys())
            del self.detection_history[oldest_frame]

    def _initiate_track_3d(self, detection,emb=None):
        self.kf_3d = KalmanBoxTracker(detection.bbox)
        self.additional_info = detection.additional_info
        pose = np.concatenate(self.kf_3d.kf.x[:7], axis=0)
        self.tracks_3d.append(Track_3D(pose, self.kf_3d, self.track_id_3d, self.n_init, self.max_age,self.additional_info,emb))
        self.track_id_3d += 2

    def _initiate_track_2d(self, detection,emb):
        mean, covariance = self.kf_2d.initiate(detection.to_xyah())
        self.tracks_2d.append(Track_2D(mean, covariance, self.track_id_2d, self.n_init, self.max_age,emb))
        self.track_id_2d += 2
    
    def _identify_scene_type(self, detections, tracks):
        """
        è¯†åˆ«åœºæ™¯ç±»å‹ (ä½é€Ÿ/ä¸­é€Ÿ/é«˜é€Ÿ)
        
        Returns:
            scene_type: 'low_speed_stable', 'medium_speed_mixed', 'high_speed_unstable'
        """
        if len(tracks) == 0:
            return 'unknown'
        
        # è®¡ç®—å¹³å‡é€Ÿåº¦å’Œé€Ÿåº¦æ³¢åŠ¨
        velocities = []
        for trk in tracks:
            vel = get_velocity(trk)
            speed = np.linalg.norm(vel)
            velocities.append(speed)
        
        avg_speed = np.mean(velocities)
        speed_std = np.std(velocities) if len(velocities) > 1 else 0
        
        # åœºæ™¯åˆ†ç±»
        if avg_speed < 5.0 and speed_std < 1.0:
            return 'low_speed_stable'      # ä½é€Ÿç¨³å®š
        elif avg_speed < 15.0 and speed_std < 3.0:
            return 'medium_speed_mixed'    # ä¸­é€Ÿæ··åˆ
        else:
            return 'high_speed_unstable'   # é«˜é€Ÿä¸ç¨³å®š
    
    def _get_adaptive_backtrack_config(self, scene_type):
        """
        æ ¹æ®åœºæ™¯ç±»å‹è¿”å›è‡ªé€‚åº”çš„å›æº¯å‚æ•°
        
        Args:
            scene_type: åœºæ™¯ç±»å‹
        
        Returns:
            config: é…ç½®å­—å…¸
        """
        if scene_type == 'low_speed_stable':
            return {
                'velocity_weight': 0.3,
                'position_weight': 0.7,
                'velocity_threshold': self.adaptive_threshold_low,
                'max_backtrack_age': 30,
                'enable_backtrack': True
            }
        elif scene_type == 'medium_speed_mixed':
            return {
                'velocity_weight': 0.4,
                'position_weight': 0.6,
                'velocity_threshold': self.adaptive_threshold_mid,
                'max_backtrack_age': 20,
                'enable_backtrack': True
            }
        else:  # high_speed_unstable
            return {
                'velocity_weight': 0.5,
                'position_weight': 0.5,
                'velocity_threshold': self.adaptive_threshold_high,
                'max_backtrack_age': 10,
                'enable_backtrack': True
            }
    
    def _compute_acceleration(self, track):
        """
        è®¡ç®—è½¨è¿¹çš„åŠ é€Ÿåº¦
        ä½¿ç”¨é€Ÿåº¦å†å²è®¡ç®—: a = (v_new - v_old) / æ¡†å¸§å·®
        
        Args:
            track: è½¨è¿¹å¯¹è±¡
        
        Returns:
            acceleration: 3D åŠ é€Ÿåº¦å‘é‡
        """
        if not hasattr(track, 'velocity_history') or len(track.velocity_history) < 2:
            return np.zeros(3)
        
        # è·å–æœ€è¿‘çš„ä¸¤ä¸ªé€Ÿåº¦
        recent_vel = track.velocity_history[-1][1]  # æœ€æ–°é€Ÿåº¦
        prev_vel = track.velocity_history[-2][1]    # å‰ä¸€ä¸ªé€Ÿåº¦
        
        # è®¡ç®—æ¡†å¸§å·®
        recent_frame = track.velocity_history[-1][0]
        prev_frame = track.velocity_history[-2][0]
        frame_diff = max(recent_frame - prev_frame, 1)  # ä¸èƒ½ä¸º0
        
        # è®¡ç®—åŠ é€Ÿåº¦
        acceleration = (recent_vel - prev_vel) / frame_diff
        
        return acceleration